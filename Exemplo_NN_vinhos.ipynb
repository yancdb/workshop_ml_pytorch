{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sb1OHNl8W-lW"
      },
      "source": [
        "# Um exemplo básico"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb7OsGclfSIP"
      },
      "source": [
        "Este notebook aborda a análise de um conjunto de dados relacionado à **qualidade de vinhos tintos**. O objetivo principal é entender como diferentes características químicas e físicas do vinho influenciam sua qualidade, que é avaliada por especialistas em uma escala de 0 a 10.\n",
        "\n",
        "### Descrição da Tabela\n",
        "\n",
        "A tabela contém **11 variáveis preditoras** e **1 variável alvo** (`quality`), descritas a seguir:\n",
        "\n",
        "| **Coluna**               | **Descrição**                                    |\n",
        "|--------------------------|--------------------------------------------------|\n",
        "| `fixed acidity`          | Acidez fixa do vinho (ex.: ácido tartárico).     |\n",
        "| `volatile acidity`       | Acidez volátil, relacionada ao ácido acético.    |\n",
        "| `citric acid`            | Presença de ácido cítrico (afeta sabor e aroma). |\n",
        "| `residual sugar`         | Quantidade de açúcar residual no vinho.          |\n",
        "| `chlorides`              | Concentração de cloretos (sal).                  |\n",
        "| `free sulfur dioxide`    | Dióxido de enxofre livre (previne oxidação).     |\n",
        "| `total sulfur dioxide`   | Total de dióxido de enxofre presente.            |\n",
        "| `density`                | Densidade do vinho.                              |\n",
        "| `pH`                     | Indicador de acidez do vinho.                    |\n",
        "| `sulphates`              | Nível de sulfatos (relacionado à conservação).   |\n",
        "| `alcohol`                | Teor alcoólico do vinho (% em volume).           |\n",
        "| `quality`                | Qualidade do vinho, avaliada por especialistas.  |\n",
        "\n",
        "\n",
        "Abaixo, segue um exemplo de como podemos usar redes neurais para aprender a relação entre as propiedades do vinho e sua qualidade. O modelo treinado sera capaz de prever a qualidade de um vinho, apenas usando essas propiedades.\n",
        "\n",
        "$\n",
        "  \\text{Qualidade}= \\text{model}(\\text{Propiedades})\n",
        "$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MxlGlvIwWII3",
        "outputId": "90d45a2f-80ab-420d-9140-907993302663",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-22 23:56:49--  https://github.com/Esterci/workshop_ml_pytorch/blob/main/winequality-red.csv\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘winequality-red.csv.1’\n",
            "\n",
            "winequality-red.csv     [ <=>                ] 270.41K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-10-22 23:56:50 (2.68 MB/s) - ‘winequality-red.csv.1’ saved [276898]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/Esterci/workshop_ml_pytorch/blob/main/winequality-red.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "1w4D1-4qLtVb",
        "outputId": "c21f0569-1522-45c1-e1b5-9d22461f6678"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "Error tokenizing data. C error: Expected 1 fields in line 38, saw 2\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-341922505.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Carregar o dataset com o separador correto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'winequality-red.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Definir características (X) e alvo (y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1921\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1922\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1925\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 38, saw 2\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Carregar o dataset com o separador correto\n",
        "file_path = 'winequality-red.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "print(data.head())\n",
        "# Definir características (X) e alvo (y)\n",
        "X = data.drop(columns=['quality']).values\n",
        "y = data['quality'].values\n",
        "\n",
        "# Dividir os dados em conjuntos de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i017i3YbG9KA"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Converter os dados para tensores PyTorch\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)  # Formato adequado para MSE\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# Definir uma rede neural simples\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, 1)  # Saída única para regressão\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Inicializar o modelo\n",
        "input_size = X_train.shape[1]\n",
        "model = SimpleNN(input_size)\n",
        "\n",
        "# Definir função de perda e otimizador\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Treinar o modelo com visualização de perda\n",
        "epochs = 500\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "i=0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Modo de treinamento\n",
        "    model.train()\n",
        "    outputs = model(X_train_tensor)\n",
        "    loss = torch.mean(torch.abs(outputs - y_train_tensor))\n",
        "\n",
        "    # Backprop e otimização\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    # Avaliação no conjunto de validação\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_predictions = model(X_test_tensor)\n",
        "        val_loss = criterion(val_predictions, y_test_tensor)\n",
        "        val_losses.append(val_loss.item())\n",
        "    if(i%100==0):\n",
        "      print(f\"Época {epoch+1}/{epochs}, Perda Treino: {loss.item():.4f}, Perda Validação: {val_loss.item():.4f}\")\n",
        "    i+=1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Visualização das perdas de treino e validação\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_losses, label='Perda de Treino')\n",
        "plt.plot(val_losses, label='Perda de Validação')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Perda')\n",
        "plt.title('Evolução da Perda durante o Treinamento')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Avaliar o modelo no conjunto de teste\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    predictions = model(X_test_tensor).squeeze()\n",
        "    test_loss = criterion(predictions, y_test_tensor.squeeze())\n",
        "\n",
        "    print(f\"Perda no Conjunto de Teste: {test_loss.item():.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Visualização da validação (valores reais vs. preditos)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, predictions.numpy() , alpha=0.2, edgecolor='k')\n",
        "plt.ylim(3,9)\n",
        "plt.xlabel('Valores Reais')\n",
        "plt.ylabel('Valores Preditos')\n",
        "plt.title('Real vs Predito no Conjunto de Teste')\n",
        "plt.show()\n",
        "\n",
        "predictions=predictions.numpy().round()\n",
        "# Visualização da validação (valores reais vs. preditos)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, predictions , alpha=0.2, edgecolor='k')\n",
        "plt.ylim(3,9)\n",
        "plt.xlabel('Categorias Reais')\n",
        "plt.ylabel('Categorias Preditos')\n",
        "plt.title('Real vs Predito no Conjunto de Teste')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oshq3R9-SCxU"
      },
      "source": [
        "## Um Desafio: Como visualizar bem os dados e resultados?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCE2SIQlSLYd"
      },
      "source": [
        "### Adicionando Um pouquinho de barulho nos valores inteiros\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rymsOBKSy-U"
      },
      "outputs": [],
      "source": [
        "\n",
        "noise = np.random.uniform(-0.1, 0.1, size=y_test.shape)  # Noise with mean 0 and std 0.5\n",
        "noise2 = np.random.uniform(-0.1, 0.1, size=y_test.shape)  # Noise with mean 0 and std 0.5\n",
        "\n",
        "\n",
        "\n",
        "# Visualização da validação (valores reais vs. preditos)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test+noise, predictions+noise2, alpha=0.1, edgecolor='k')\n",
        "plt.ylim(3,9)\n",
        "plt.xlabel('Valores Reais')\n",
        "plt.ylabel('Valores Preditos')\n",
        "plt.title('Real vs Predito no Conjunto de Teste')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8yvC1pGSIn5"
      },
      "source": [
        "### Histograma de erros por categoria\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MMvRCH5OLTD"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Calcular os erros (diferença entre valores reais e preditos)\n",
        "errors = y_test - predictions\n",
        "\n",
        "# Definir o intervalo de valores para os quais queremos plotar os histogramas\n",
        "values_range = np.arange(3, 9)  # Intervalo de valores reais [3, 4, ..., 9]\n",
        "\n",
        "# Criar a figura com múltiplos subgráficos\n",
        "plt.figure(figsize=(15, 10))\n",
        "# Loop para plotar um histograma para cada valor de 3 a 9\n",
        "for i, value in enumerate(values_range):\n",
        "    # Filtrar os erros para o valor atual\n",
        "    value_errors = errors[y_test == value]\n",
        "\n",
        "    # Criar um subgráfico\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    plt.hist(value_errors, bins=10, alpha=0.7, edgecolor='black', color='blue')\n",
        "    plt.title(f'Erro para Valor Real = {value}')\n",
        "    plt.xlabel('Erro (Real - Predito)')\n",
        "    plt.ylabel('Frequência')\n",
        "    plt.grid(True)\n",
        "\n",
        "# Ajustar layout e exibir o gráfico\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eTiZsYuWUlJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "# Loop para plotar um histograma para cada valor de 3 a 9\n",
        "for i, value in enumerate(values_range):\n",
        "    # Filtrar os erros para o valor atual\n",
        "    value_errors = errors[y_test == value]\n",
        "\n",
        "    # Criar um subgráfico\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    plt.hist(predictions[y_test == value], bins=10, alpha=0.7, edgecolor='black', color='blue')\n",
        "    plt.title(f'Valor Real = {value}')\n",
        "    plt.xlabel('Predito')\n",
        "    plt.ylabel('Frequência')\n",
        "    plt.grid(True)\n",
        "\n",
        "# Ajustar layout e exibir o gráfico\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFgKZJSvdj4s"
      },
      "source": [
        "## Pergunta:\n",
        "\n",
        "\n",
        "*   Para quais classificações o modelo acertou e errou mais?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjL8q53xXDxq"
      },
      "source": [
        "#Exercício\n",
        "\n",
        "##Usando Redes Mais Complexas\n",
        "\n",
        "Refaça a implementação anterior usando modelos com redes maiores para melhorar os resultados observados!\n",
        "\n",
        "Dicas:\n",
        "\n",
        "*   Siga o passo a passo indicado no tempate, use o exemplo anterior como referência de sintaxe.\n",
        "\n",
        "\n",
        "*   Use e modifique o LargeModel do exemplo abaixo! Experimente adicionar mais camadas, aumentar o numero de neurons por camada, ou trocar a função de ativação!\n",
        "\n",
        "*   Modelos maiores geralmente precisam treinar por mais tempo, experimente aumentar o numero de iterações de treino."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhn_SchWZu8a"
      },
      "outputs": [],
      "source": [
        "##Modelo Maior\n",
        "class LargeNN(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, 1)  # Saída única para regressão\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4JSICTbZ06a"
      },
      "source": [
        "## Template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7mPEdbiWII5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "######### Passo 1: Carrege os dados da tabela #############\n",
        "\n",
        "# Carregar o dataset com o separador correto\n",
        "file_path = 'winequality-red.csv'\n",
        "data = pd.read_csv(file_path, sep=';')\n",
        "print(data.head())\n",
        "\n",
        "# Definir características (X) e alvo (y)\n",
        "X = data.drop(columns=['quality']).values\n",
        "y = data['quality'].values\n",
        "\n",
        "# Dividir os dados em conjuntos de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Converter em tensores\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)  # Formato adequado para MSE\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "\n",
        "######### Passo 2: Defina o modelo #############\n",
        "\n",
        "# Definir uma rede neural simples\n",
        "class NN(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(NN, self).__init__()\n",
        "        ##Definir cada uma das camadas\n",
        "\n",
        "    def forward(self, x):\n",
        "        ## Definir foward pass\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "######### Passo 3: Treine o modelo #############\n",
        "\n",
        "# Inicializar o modelo\n",
        "input_size = X_train.shape[1]\n",
        "model = NN(input_size)\n",
        "\n",
        "# Definir função de perda e otimizador\n",
        "\n",
        "\n",
        "## Treinar o modelo\n",
        "##Dica comece fazendo apenas uma iteração de treino depois ponha em um loop\n",
        "\n",
        "  ###Loop de treino\n",
        "  ### Use a rede para prever valores para o conjunto de treino\n",
        "  ### Compare essa previsao com o y_train_tensor (valor verdadeiro)\n",
        "      ###Dica: Aqui voce pode usar uma expressão, como no exemplo ou usar essas funções prontas  nn.CrossEntropyLoss(),nn.MAELoss(),nn.L1Loss()   Alternativamente em vez de chamar criteion posso simplesmente chamar uma expressão de y_test e predicicao\n",
        "      ### no caso a sintaxe é loss=nn.MAELoss(y_test_tensor,predicao)\n",
        "\n",
        "  ### Use zerograd e backward para calcular o gradient\n",
        "  ### Use o otimizador para atualizar o parametro\n",
        "\n",
        "\n",
        "##Use o modelo Treinado para Validaçao\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    predictions = model(X_test_tensor).squeeze()\n",
        "    test_loss = criterion(predictions, y_test_tensor.squeeze())\n",
        "\n",
        "    print(f\"Perda no Conjunto de Teste: {test_loss.item():.4f}\")\n",
        "\n",
        "\n",
        "### Visualize os resultados do modelo\n",
        "    ###Dica: use os histogramas para comparar efitavamente a perfomance do seu modelo com o do exemplo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwZYjME_dwCu"
      },
      "source": [
        "## Pergunta:\n",
        "\n",
        "\n",
        "*   Qual foi o efeito de aumentar a complexidade do modelo na acurácia final e no tempo de treino?\n",
        "\n",
        "*   Se testou alguma função perda diferente, qual foi o efeito?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiZWJCzXZ0Hi"
      },
      "source": [
        "## Extra\n",
        "  Use a outra tabela winequality-white.csv para repetir o processo com o vinhos brancos. Em qual cenário o modelo é mais correto?\n",
        "  \n",
        "\n",
        "*   Voce pode modularizar (transformar em funções) todo o processo, parametrizando o dataset alvo. Assim pode chamar uma vez o processo para cada tabela e comparar os resultados.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSzmNiTzWII6"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "PCE2SIQlSLYd"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}